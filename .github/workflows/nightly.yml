name: nightly-simnet

on:
  schedule:
    # Mondays at 01:30 UTC
    - cron: '30 1 * * 1'
  workflow_dispatch:

jobs:
  timetoke-slo-report:
    name: Timetoke replay SLO report
    runs-on: ubuntu-latest
    env:
      TIMETOKE_PROMETHEUS_URL: ${{ secrets.TIMETOKE_PROMETHEUS_URL }}
      TIMETOKE_PROMETHEUS_BEARER: ${{ secrets.TIMETOKE_PROMETHEUS_BEARER }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install stable toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Generate Timetoke SLO report
        run: |
          set -euo pipefail
          if [ -n "${TIMETOKE_PROMETHEUS_URL:-}" ]; then
            cargo xtask report-timetoke-slo \
              --prometheus-url "${TIMETOKE_PROMETHEUS_URL}" \
              --output timetoke-slo-report.md
          else
            cargo xtask report-timetoke-slo \
              --metrics-log docs/observability/examples/timetoke_metrics.jsonl \
              --output timetoke-slo-report.md
          fi

      - name: Upload SLO report
        uses: actions/upload-artifact@v4
        with:
          name: timetoke-slo-report
          path: timetoke-slo-report.md

  snapshot-health:
    name: Snapshot stream health audit
    if: ${{ secrets.SNAPSHOT_RPC_URL != '' }}
    runs-on: ubuntu-latest
    env:
      SNAPSHOT_RPC_URL: ${{ secrets.SNAPSHOT_RPC_URL }}
      SNAPSHOT_RPC_TOKEN: ${{ secrets.SNAPSHOT_RPC_TOKEN }}
      SNAPSHOT_MANIFEST_PATH: ${{ secrets.SNAPSHOT_MANIFEST_PATH }}
      SNAPSHOT_MANIFEST_JSON: ${{ secrets.SNAPSHOT_MANIFEST_JSON }}
      SNAPSHOT_VALIDATOR_CONFIG: ${{ secrets.SNAPSHOT_VALIDATOR_CONFIG }}
      SNAPSHOT_CHUNK_ARCHIVE_URL: ${{ secrets.SNAPSHOT_CHUNK_ARCHIVE_URL }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install stable toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Build rpp-node CLI
        run: |
          set -euo pipefail
          cargo build -p rpp-node --release

      - name: Verify pruning snapshot archive secret
        id: pruning-chunks
        run: |
          set -euo pipefail

          if [ -z "${SNAPSHOT_CHUNK_ARCHIVE_URL:-}" ]; then
            echo "::warning::SNAPSHOT_CHUNK_ARCHIVE_URL is not configured; skipping pruning snapshot chunk download" >&2
            echo "enabled=false" >>"${GITHUB_OUTPUT}"
          else
            echo "enabled=true" >>"${GITHUB_OUTPUT}"
          fi

      - name: Download pruning snapshot chunks
        if: steps.pruning-chunks.outputs.enabled == 'true'
        run: |
          set -euo pipefail

          workspace="${GITHUB_WORKSPACE:-$(pwd)}"
          staging_root="${workspace}/target/pruning-snapshot-chunks"
          rm -rf "${staging_root}"
          mkdir -p "${staging_root}"

          tmp_dir="$(mktemp -d)"
          cleanup() {
            rm -rf "${tmp_dir}"
          }
          trap cleanup EXIT

          archive_path="${tmp_dir}/snapshot-chunks"
          extract_dir="${tmp_dir}/extracted"
          mkdir -p "${extract_dir}"

          strip_url_suffix() {
            local value="$1"
            local without_fragment="${value%%#*}"
            local without_query="${without_fragment%%\?*}"
            if [ -n "${without_query}" ]; then
              echo "${without_query}"
            else
              echo "${value}"
            fi
          }

          extract_archive() {
            local source="$1"
            local archive="$2"
            local destination="$3"

            case "${source}" in
              *.tar|*.tar.gz|*.tgz|*.tar.xz)
                tar -xf "${archive}" -C "${destination}"
                ;;
              *.tar.zst|*.tzst)
                if command -v unzstd >/dev/null 2>&1; then
                  tar --use-compress-program=unzstd -xf "${archive}" -C "${destination}"
                elif command -v zstdcat >/dev/null 2>&1; then
                  zstdcat "${archive}" | tar -x -C "${destination}"
                else
                  echo "::error::zstd utilities are required to extract ${source}" >&2
                  exit 1
                fi
                ;;
              *.zip)
                unzip -q "${archive}" -d "${destination}"
                ;;
              *)
                echo "::error::Unsupported archive type for ${source}" >&2
                exit 1
                ;;
            esac
          }

          source_for_type="$(strip_url_suffix "${SNAPSHOT_CHUNK_ARCHIVE_URL}")"

          is_archive=false
          case "${source_for_type}" in
            *.tar|*.tar.gz|*.tgz|*.tar.xz|*.tar.zst|*.tzst|*.zip)
              is_archive=true
              ;;
          esac

          echo "Fetching pruning snapshot chunks from ${SNAPSHOT_CHUNK_ARCHIVE_URL}" >&2
          if [[ "${SNAPSHOT_CHUNK_ARCHIVE_URL}" == s3://* ]]; then
            if ! command -v aws >/dev/null 2>&1; then
              echo "aws CLI not found; installing with pip" >&2
              python3 -m pip install --user --upgrade awscli
              export PATH="${HOME}/.local/bin:${PATH}"
              hash -r
            fi

            if [[ "${is_archive}" == true ]]; then
              aws s3 cp --no-progress "${SNAPSHOT_CHUNK_ARCHIVE_URL}" "${archive_path}"
              extract_archive "${source_for_type}" "${archive_path}" "${extract_dir}"
            else
              aws s3 sync --only-show-errors "${SNAPSHOT_CHUNK_ARCHIVE_URL}" "${extract_dir}"
            fi
          else
            if [[ "${is_archive}" == true ]]; then
              curl -fL "${SNAPSHOT_CHUNK_ARCHIVE_URL}" -o "${archive_path}"
              extract_archive "${source_for_type}" "${archive_path}" "${extract_dir}"
            else
              echo "::error::Unsupported archive type for ${SNAPSHOT_CHUNK_ARCHIVE_URL}" >&2
              exit 1
            fi
          fi

          if [ -z "$(find "${extract_dir}" -mindepth 1 -maxdepth 1 -print -quit)" ]; then
            echo "::error::No pruning snapshot files extracted from ${SNAPSHOT_CHUNK_ARCHIVE_URL}" >&2
            exit 1
          fi

          find "${staging_root}" -mindepth 1 -delete
          cp -a "${extract_dir}/." "${staging_root}/"

          chunk_root="${staging_root}"
          detected_chunk_dir="$(find "${staging_root}" -type d -name 'cf_pruning_snapshots' | head -n 1)"
          if [ -n "${detected_chunk_dir}" ]; then
            chunk_root="${detected_chunk_dir}"
          fi

          if [ ! -d "${chunk_root}" ]; then
            echo "::error::Unable to locate pruning snapshot directory under ${staging_root}" >&2
            exit 1
          fi

          if [ -z "$(find "${chunk_root}" -maxdepth 1 -type f \( -name '*.json' -o -name '*.chunk' \) -print -quit)" ]; then
            echo "::warning::Pruning snapshot directory ${chunk_root} does not contain manifest or chunk files" >&2
          fi

          echo "SNAPSHOT_CHUNK_ROOT=${chunk_root}" >> "${GITHUB_ENV}"
          echo "Pruning snapshot chunks extracted to ${chunk_root}" >&2

      - name: Audit snapshot sessions
        run: |
          set -euo pipefail
          CONFIG_PATH="${SNAPSHOT_VALIDATOR_CONFIG:-config/validator.toml}"
          cargo xtask snapshot-health \
            --config "${CONFIG_PATH}" \
            --output snapshot-health-report.json \
            --rpp-node-bin target/release/rpp-node

      - name: Upload snapshot health report
        uses: actions/upload-artifact@v4
        with:
          name: snapshot-health-report
          path: snapshot-health-report.json

  phase3-evidence:
    name: Phase 3 evidence bundle
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install stable toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Collect compliance evidence
        run: |
          set -euo pipefail
          cargo xtask collect-phase3-evidence

      - name: Prepare evidence metadata
        id: phase3
        run: |
          set -euo pipefail
          base_dir="target/compliance/phase3"
          if [ ! -d "$base_dir" ]; then
            echo "::error::No evidence bundles generated" >&2
            exit 1
          fi
          latest_dir=$(ls -1 "$base_dir" | grep -E '^[0-9]{8}T[0-9]{6}Z$' | sort | tail -n 1)
          if [ -z "$latest_dir" ]; then
            echo "::error::No timestamped evidence directories found" >&2
            exit 1
          fi
          manifest_path="$base_dir/$latest_dir/manifest.json"
          bundle_path="$base_dir/phase3-evidence-$latest_dir.tar.gz"
          if [ ! -f "$manifest_path" ]; then
            echo "::error::Evidence manifest $manifest_path is missing" >&2
            exit 1
          fi
          if [ ! -f "$bundle_path" ]; then
            echo "::error::Evidence bundle $bundle_path is missing" >&2
            exit 1
          fi
          echo "timestamp=$latest_dir" >>"$GITHUB_OUTPUT"
          echo "manifest=$manifest_path" >>"$GITHUB_OUTPUT"
          echo "bundle=$bundle_path" >>"$GITHUB_OUTPUT"

      - name: Upload Phase 3 evidence bundle
        uses: actions/upload-artifact@v4
        with:
          name: phase3-evidence-${{ steps.phase3.outputs.timestamp }}
          path: |
            ${{ steps.phase3.outputs.manifest }}
            ${{ steps.phase3.outputs.bundle }}

  plonky3-hash-audit:
    name: Plonky3 release hash audit
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Determine latest release tag
        id: release
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          tag=$(gh release view --json tagName --jq '.tagName')
          if [[ -z "$tag" ]]; then
            echo "::error::Unable to determine latest release tag" >&2
            exit 1
          fi
          echo "tag=$tag" >>"$GITHUB_OUTPUT"
      - name: Download release manifests
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          mkdir -p dist/release
          gh release download "${{ steps.release.outputs.tag }}" \
            --pattern 'plonky3-setup-hashes.json*' \
            --pattern 'SHA256SUMS.txt*' \
            --dir dist/release
      - uses: sigstore/cosign-installer@v3
        with:
          cosign-release: 'v2.4.0'
      - name: Verify checksum manifest signature
        env:
          COSIGN_EXPERIMENTAL: "1"
        run: |
          set -euo pipefail
          cosign verify-blob \
            --certificate dist/release/SHA256SUMS.txt.pem \
            --signature dist/release/SHA256SUMS.txt.sig \
            dist/release/SHA256SUMS.txt
      - name: Verify Plonky3 hash manifest signature
        env:
          COSIGN_EXPERIMENTAL: "1"
        run: |
          set -euo pipefail
          cosign verify-blob \
            --certificate dist/release/plonky3-setup-hashes.json.pem \
            --signature dist/release/plonky3-setup-hashes.json.sig \
            dist/release/plonky3-setup-hashes.json
      - name: Compute repository hash manifest
        run: |
          set -euo pipefail
          python3 scripts/generate_plonky3_artifacts.py \
            config/plonky3/setup \
            --verify \
            --hash-output dist/local-plonky3-setup-hashes.json
      - name: Compare repository and release manifests
        run: |
          set -euo pipefail
          if ! cmp -s dist/local-plonky3-setup-hashes.json dist/release/plonky3-setup-hashes.json; then
            echo "::error::Repository and release Plonky3 hash manifests differ" >&2
            diff -u dist/release/plonky3-setup-hashes.json dist/local-plonky3-setup-hashes.json || true
            exit 1
          fi
      - name: Validate checksum entry for hash manifest
        run: |
          set -euo pipefail
          release_sha=$(grep ' dist/plonky3-setup-hashes.json$' dist/release/SHA256SUMS.txt | awk '{print $1}')
          if [[ -z "$release_sha" ]]; then
            echo "::error::SHA256SUMS.txt does not contain dist/plonky3-setup-hashes.json" >&2
            exit 1
          fi
          local_sha=$(sha256sum dist/local-plonky3-setup-hashes.json | awk '{print $1}')
          if [[ "$release_sha" != "$local_sha" ]]; then
            echo "::error::Checksum mismatch for dist/plonky3-setup-hashes.json" >&2
            echo "release: $release_sha" >&2
            echo "local:   $local_sha" >&2
            exit 1
          fi
  validation:
    name: Nightly validation (${{ matrix.name }})
    runs-on: ubuntu-latest
    continue-on-error: ${{ matrix.experimental }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: default
            features: ""
            no_default_features: ""
            experimental: false
          - name: prod-stwo
            features: "prod,prover-stwo"
            no_default_features: "1"
            experimental: false
          - name: prod-stwo-plonky3
            features: "prod,prover-stwo,backend-plonky3"
            no_default_features: "1"
            experimental: true
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install stable toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Execute xtask test-all
        run: |
          set -euo pipefail
          if [ -n "${{ matrix.no_default_features }}" ]; then
            export XTASK_NO_DEFAULT_FEATURES="${{ matrix.no_default_features }}"
          fi
          if [ -n "${{ matrix.features }}" ]; then
            export XTASK_FEATURES='${{ matrix.features }}'
          fi
          cargo xtask test-all

  plonky3-gpu:
    name: Plonky3 GPU smoke
    runs-on: ubuntu-latest
    env:
      RUSTFLAGS: "-C debuginfo=0"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install stable toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Build GPU backend
        run: |
          set -euo pipefail
          cargo build -p plonky3-backend --no-default-features --features plonky3-gpu

      - name: GPU backend smoke test
        run: |
          set -euo pipefail
          cargo test -p plonky3-backend --no-default-features --features plonky3-gpu -- consensus_proof_metadata_tracks_commitment_digest

  simnet:
    name: Simnet harness (prod, prover-stwo, plonky3)
    runs-on: ubuntu-latest
    env:
      XTASK_NO_DEFAULT_FEATURES: "1"
      XTASK_FEATURES: "prod,prover-stwo,backend-plonky3"
      RUSTFLAGS: "-C debuginfo=0"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install stable toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Execute simnet harness
        run: |
          set -euo pipefail
          cargo xtask test-simnet

      - name: Analyze summaries
        run: |
          set -euo pipefail
          python3 scripts/analyze_simnet.py \
            target/simnet/ci-block-pipeline/summaries/ci-block-pipeline.json \
            target/simnet/ci-state-sync-guard/summaries/ci-state-sync-guard.json \
            target/simnet/consensus-quorum-stress/summaries/consensus_quorum_stress.json \
            target/simnet/snapshot-partition/summaries/snapshot_partition.json

      - name: Package artifacts
        run: |
          tar -czf simnet-artifacts.tar.gz -C target simnet

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: simnet-nightly
          path: simnet-artifacts.tar.gz

  simnet-regression:
    name: Simnet regression (prod, plonky3)
    runs-on: ubuntu-latest
    env:
      RUSTFLAGS: "-C debuginfo=0"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Install stable toolchain
        uses: dtolnay/rust-toolchain@stable
      - name: Execute regression sweep
        run: |
          set -euo pipefail
          rm -rf target/simnet/regression-nightly
          cargo run -p simnet --bin regression -- \
            --artifacts-root target/simnet/regression-nightly
      - name: Package regression artifacts
        run: |
          tar -czf simnet-regression.tar.gz -C target/simnet regression-nightly
      - name: Upload regression archive
        uses: actions/upload-artifact@v4
        with:
          name: simnet-regression-nightly
          path: simnet-regression.tar.gz
